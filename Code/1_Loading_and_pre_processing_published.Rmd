---
title: "1_loading_and_pre_processing"
author: "Pedro Beschoren da Costa"
date: "August 24, 2021"
output: html_document
editor_options: 
  chunk_output_type: console
---
## 0 - Loading  R Libraries
If a package is installed, it will be loaded. If any are not installed, the missing package(s) will be installed 
from CRAN and then loaded.
```{r results=hide}

#test git

## First specify the packages of interest
packages <- c("devtools",# needed to install some packages
             "BiocManager", # needed to install some packages
             "remotes",# needed to install some packages
             "ggplot2",
             "dplyr",
             "tibble", 
             "stringr",# to wrangle string vectors
             "Boruta", # for random forest feature selection
             "mlbench", # for random forest
             "caret", # for random forest
             "randomForest", # for random forest
             "tidyr",
             "vegan", # for several essential statistical tests
             "forcats",
             "ggrepel", # to avoid legends overlapping in your plot
             "ggpubr",
             "igraph", # calculates entowrk metrics and manipulates netowrk objects
             "WGCNA", # needed for eigen_correlation (), allowing you to correlate metadata to network modules
             "metagMisc", #  lets you create lists of split phyloseq objects
             "pheatmap", # heatmaps for deseq2
             "viridis", # nice colors
             "agricolae",# includes some anova post-hoc options
             "minpack.lm", #lets you do som HSD tests, output is a nive table
             "Hmisc", # for neutral models
             "spaa", # need to install Ecoutils
             "stats4",# for neutral models
             "car", #for levene test
             "indicspecies", #runs indicator species analysis
             "metacoder", # plots heat trees
             "purrr", # has map() to select table elements
             "viridis") # prety colors for deseq2 heatmaps



## Now load or install & load packages 
lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  }
)


biocManager_packages <- c(
             "phyloseq", # essential to produce phyloseq objects with OTU, metadata, and taxa info in one single place
             "microbiome", # has convinient data wrangling functions
             "decontam", # to make use of no-template blank DNA extractions
             "metagenomeSeq", # to normalize library sizes without rarefying them
             "DESeq2") # used for differential abundance analysis

## Now load or install & load packages managed by BiocManager
lapply(
  biocManager_packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      BiocManager::install(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  }
)


#additional packages outside CRAN or bioconductor
if (!require(pairwiseAdonis)) install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")
library("pairwiseAdonis") # has a wrapper for pairwise comparison of adonis

if (!require(tyRa)) install_github("DanielSprockett/tyRa")
library("tyRa")  #need for neutral models

if (!require(metagMisc)) devtools::install_github("vmikk/metagMisc")
library("metagMisc")  #n lets you split a phyloseq object in a list

if (!require(EcolUtils)) devtools::install_github("GuillemSalazar/EcolUtils")
library("EcolUtils")  #pairwise adonis fucntion

if (!require(MicEco)) remotes::install_github("Russel88/MicEco")
library("MicEco")  #for venn diagrams on SPSS objects

if (!require(SpiecEasi)) install_github("zdk123/SpiecEasi")
library("SpiecEasi") # builds the sparse networks


rm(packages,biocManager_packages) # we don't need this anymore so let's remove them from the environemnt

```


## 1 - Loading data 
our data (processed in qiime2) was saved in BIOM format, making importing easier since there are less files to handle


```{r results="hide"}
##### Loading Microbiome data ##########

# This will load all the essential data (OTU frequencies, representative sequences, mapping files with metadata, taxonomy, phylogenetic tree) for a single phyloseq object
physeq<-import_biom("./Data/Pilot_phyloseq_input_FeatureTable_metadata_taxonomy.biom",
                    #treefilename="./Data/tree.nwk", # we havent'really used the tree, and it makes merging of phyloseq object complicated. thus, we are not loading it inside R
                    refseqfilename="./Data/dna-sequences.fasta")

physeq #Give a look to the object
refseq(physeq) #example


# let's check the imported objects. Often errors will arise from typos when filling up the data sheets 
head(otu_table(physeq))
head(sample_data(physeq)) #Metadata information
head(tax_table(physeq)) #IDs and taxonomy


# note that dada2 will give us horrible OTU names, let's change this with a custom function
source("./Code/Functions/backup_and_rename.R") # source will load the function inside the Code folder of this R project

#this will run the custom fucntion and update the physeq object
physeq<-backup_and_rename(physeq) # this function runs slow sinde the chuck but fast on the console.... to solve this, click on the gear and set "chucnk output in teh console" instead of "chunk output inline"


#we must now adjust some factors as numeric because some functions will only work if their input is in the right category
sample_data(physeq)$Baseclear_DNA_concentration_ngul<-as.numeric(sample_data(physeq)$Baseclear_DNA_concentration_ngul)

```


### 1.1 Decontamination process
Decontamination with the decontam package only removed a single OTU from analysis. This is because we did not have enough blank DNA extraction samples. we continue to use this filtering regardless of it's low performance.


```{r}
# Before we proceed, let's prepere phyloseq object for decontamination using the decontam package
physeq_norm<-transform_sample_counts(physeq, function(OTU) OTU/sum(OTU)) # transforms to relative frequency
colSums(otu_table(physeq_norm)) # checks if sums are 1
sample_data(physeq_norm)$is.neg <- ssample_data(physeq_norm)$Plant_specie== "Blank" # set negatives as TRUE in a  new column
tail(sample_data(physeq_norm)$is.neg) #Checking that last sample is indeed TRUE


# decontaminate! read details on decontam package. use at least 3 blank samples for minimal decontamination. grouping your blanks in batches (such as sampling blanks, DNA extraction blanks, PCR blanks) can help you remove contaminants according different sources. Try to obtain the DNA concentration from the PCR product to include this variable in the decontamination process.
decontam_output <- isContaminant(physeq_norm,
                                         neg="is.neg",
                                         threshold=0.1) # using 0.1  gave us only one single contaminant
table(decontam_output$contaminant) # this shows the number of  contaminates (=TRUE)
head(decontam_output) # checks decontam output

contaminants <- rownames(subset(decontam_output, contaminant%in%c("TRUE")))
contaminants #this is a list of otus classified as contaminants


# Make phyloseq object of presence-absence (pa) in negative controls and true samples
physeq_norm_pa <- transform_sample_counts(physeq_norm, function(abund) 1*(abund>0))
physeq_norm_pa_neg <- prune_samples(sample_data(physeq_norm_pa)$Plant_species == "Blank", 
                                                 physeq_norm_pa)
physeq_norm_pa_pos <- prune_samples(sample_data(physeq_norm_pa)$Plant_species != "Blank", 
                                                 physeq_norm_pa)

# Make data.frame of prevalence in positive and negative samples
physeq_norm_df_pa <- data.frame(pa.pos=taxa_sums(physeq_norm_pa_pos), 
                                                pa.neg=taxa_sums(physeq_norm_pa_neg),
                                                contaminant=decontam_output$contaminant)

ggplot(data=physeq_norm_df_pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + 
  geom_point() +
  xlab("Prevalence (Negative Controls)") + 
  ylab("Prevalence (True Samples)")

#clean physeq object by removing contaminant OTUS, then remove blank sample 
physeq_decontaminated <- prune_taxa(!taxa_names(physeq) %in% contaminants, physeq) # keep only taxa that are not in the list of contaminants
physeq_decontaminated <- subset_samples(physeq_decontaminated, colSums(otu_table(physeq_decontaminated))>0) # to check if we lost samples in the way : no

#clean physeq object by removing blank samples
physeq_decontaminated <- subset_samples(physeq_decontaminated, Plant_species != "Blank")

#compare both physeq
physeq_decontaminated
physeq

# DECONTAMINATION CONCLUSION: decontamination was quite useless, removing a single ASV! a single blank per library won't be enough

#now that we finished decontamination, let's remove unecessary objects and liberate some memory
rm(physeq_norm_df_pa, physeq_norm_pa_pos,physeq_norm_pa,physeq_norm)

```


### 1.2 Chloroplast and mitochondrial DNA removal ##########
Chloroplast and mitochondria DNA can be amplified by 16s primers that target bacteria. there are many approaches to reduce this problem, such as PCR blockers called PNA clamps. sometimes this is simply not enough, depending on bacterial populations and plastid DNA. A good sequencing of leaf bacterial communities can be extremely challenging due to this problem 

Here, we remove this plant sequences according the taxonomy given to the ASV by the taxa classifier in qiime2. On this chunk we will not perform any in-depht analysis or calculation.


```{r}

# First, a quick check to detect the presence of  o__Chloroplast or f__Mitochondria
plot_bar(subset_taxa(physeq_decontaminated, Order=="o__Chloroplast"),facet_grid=~Sample_type) # this shows we do have some plastid DNA arround, plot_bar is from the phyloseq package
plot_bar(subset_taxa(physeq_decontaminated, Family=="f__Mitochondria"),facet_grid=~Sample_type) # this shows we do have some mitochndrial DNA arround

summary(
  sample_sums(subset_taxa(physeq_decontaminated, Family=="f__Mitochondria"))
  /sample_sums(physeq_decontaminated))  #percentage of mitochondrial DNA per sample
# On average is about 1.6% , minimum is 0 and maximum is 8.1%, so pretty good 


#load and run  the fucntion that will remove the plant DNA. press F2 after selecting the custom function to open it on a new tab
source("./Code/Functions/remove_Chloroplast_Mitochondria.R") 
physeq_clean<- remove_Chloroplast_Mitochondria(physeq_decontaminated)

# This will check if you still have those taxa in your phyloseq object. if the output is FALSE, then you got rid of them
"o__Chloroplast" %in% tax_table(physeq_clean)
"f__Mitochondria" %in% tax_table(physeq_clean)


```

Now your bacterial phyloseq object is rid of detectable contaminants and plant DNA. note that for fungal ITS sequences you may  have some plant or microfauna DNA in the middle of your fungal sequences!




### 1.3 Filtering out rare ASVs ##########
now that our sequences are free of contaminants and plant DNA, let's remove reads that are much too rare. Here we will use the UNOISE3 standard of removing ASVs that occur less than 8 times (https://drive5.com/usearch/manual/cmd_unoise3.html)


```{r echo=TRUE, fig.show=hold}
# to be valid, an ASV may not be a singleton
physeq_filtered<-physeq_clean#... but first let's save the non-filtered phyloseq object in separate
otu_table(physeq_filtered) <- otu_table(physeq_filtered)[which (rowSums(otu_table(physeq_filtered)) > 8),] #this drops ~3000 taxa. 

#let's see how many sequences (reads) were kept after this filtering
sum(sample_sums(physeq_filtered))/sum(sample_sums(physeq_clean))*100 

# we kept 99.2% of sequences. let's now compare the histograms
ggplot() + 
  geom_density(aes(x=sample_sums(physeq_filtered)),fill=3, alpha=0.5) + 
  geom_density(aes(x=sample_sums(physeq_clean)),fill=1, alpha=0.5) 

# there's barely noticeable difference in library sizes when the library size is ~20000 reads

```




### 1.4 Data Normalization ##########


A big challange in microbiome data is the difference in library sizes: some samples are covered more in depth than others. this means sample1 may have 12.000 sequences, while samples2 may have 150.000 sequences. This is because of the sequencing machinery, and makes the data "compositional". You must normalize this data to avoid generating artefacts. there is *extensive* literature on this topic. here we will use 2 methods: rarefaction, a classic aproach necessary for some analsyis models, and cumulative sum scaling with MetagenomeSeq. 

#### 1.4a Rarefaction & rarefying ##########
This method will cut your library sizes to the minimum library size of your sequencing effort, and then repopulate the OTU tables by picking OTUs/ASVs at random. This method effectively trows away a lot of data, so it's coming into disuse.

Still, we will use rarefied data for alpha diversity, neutral model fits, and core microiome definition

```{r}
# let's first adjust some factors
sample_data(physeq_filtered)$Sample_type<-as.factor(sample_data(physeq_filtered)$Sample_type)
sample_data(physeq_clean)$Sample_type<-as.factor(sample_data(physeq_clean)$Sample_type)

#draw rarefaction curve
# here we want to find a plateau: despite increase in the number of DNA reads, we do not increase the number of observed species. essentially, sequencing was deep enought to saturate your sampling effort.
physeq_filtered_df <- as.data.frame(otu_table(physeq_filtered))
physeq_filtered_df[1:10, 1:10]

rarecurve(t(physeq_filtered_df), 
          col = sample_data(physeq_filtered)$Sample_type, 
          label = FALSE, 
          step = 200,
          main="Rarefaction at 8678 reads, 8+ occurences, 45 out of 4943 taxa lost; 33% of sequences retained ", ylab = "Number of ASVs", xlab = "Number of DNA reads",
          abline(v = min(sample_sums(physeq_filtered)), col="red", lwd=3, lty=2)) #minimum sample size in the physeq object

#rarefraction curve is actually quite ok! we won't lose much ASV diversity if we cut at the minimal depth. of course, this is after all the filtering, which removed most rare species

# now, let's rarefy the data
set.seed(100) # set a random seed so that whenever you re-run this code you draw the same set of OTUs
min(sample_sums(physeq_filtered)) #minumum library size
sort.default(colSums(otu_table(physeq_filtered))) # sometimes you might want to lose/remove one or more samples that have a very low library size. you would have to ballance the number of samples with the minimum number of sequences. in this particular dataset, we won't cut any samples as the rarefaction curve looks very good

physeq_filtered_rarefied <- rarefy_even_depth(physeq_filtered, 
                                             sample.size = min(sample_sums(physeq_filtered)), 
                                             rngseed = FALSE, replace = TRUE, 
                                             trimOTUs = TRUE, verbose = TRUE) 


# doesn't matter here, after rarefaction we can week singletons 
# this will remove any singleton randomly put in place
# otu_table(physeq_filtered_rarefied) <- otu_table(physeq_filtered_rarefied)[which                                                                        (rowSums(otu_table(physeq_filtered_rarefied)) >= 1),] 

# at this point all your samples should have an identical library size
colSums(otu_table(physeq_filtered_rarefied))

# check if any taxa has no reads (row completetly full of zeros)
any(taxa_sums(physeq_filtered_rarefied) == 0)

# this will show how much of our sequencing still makes part of our phyloseq object
sum(otu_table(physeq_filtered_rarefied))/sum(otu_table(physeq_filtered))

#this is your final phyloseq object
physeq_filtered_rarefied 
save(physeq_filtered_rarefied, file = "./Data/physeq_filtered_rarefied.Rdata")

# results of rarefraction: 45 out of 4943 ASVs lost, no samples lost. this is because we used a high filtering (option 1.3c), rarefaction curve achieved a plateau, and minimum library size was not too low.

#assing meja treatment as a factor
sample_data(physeq_filtered_rarefied)$MeJA_treatment<-as.factor(sample_data(physeq_filtered_rarefied)$MeJA_treatment)

# splits rarefied phyloseq object into several lists
pslist_sp_rarefied<-phyloseq_sep_variable(physeq_filtered_rarefied, variable = "Plant_species")
pslist_sp_rarefied

# one list of 2 phyloseq objects for root/soil samples
pslist_root_soil_rarefied<-phyloseq_sep_variable(physeq_filtered_rarefied, variable = "Sample_type") 
pslist_root_soil_rarefied

# one list of 4 phyloseq objects for sample type + species
ps_list_rarefied<-phyloseq_sep_variable(physeq_filtered_rarefied, variable = c("Plant_species","Sample_type"))

ps_list_rarefied$Arabidopsis_thaliana.Root #with $ you can call for sections/sub-sets of the list
ps_list_rarefied["Arabidopsis_thaliana.Root"] #One bracket gives you back a list of 1
ps_list_rarefied[["Arabidopsis_thaliana.Root"]] #This is not a list, only a physeq object 

##### *** THIS DATA IS NOW READY FOR ANALYSIS *** ##########

#clean environment
rm(decontam_output, physeq_decontaminated, physeq_clean, physeq, physeq_filtered_df)

```

 
#### 1.4b Metagenomseq
We use this package to be able to normalize library sizes without using rarefaction and also accounting for sparsity (high number of zeros in the dataset). This is done by considering the counts up to a certain quantile ([cumulative sum scaling, CSS](https://www.metagenomics.wiki/tools/16s/norm/css)). We will perform this with the metagenomseq package.

We will use CSS-normalized data for beta diversity analysis: ordinations, permanovas and beta dispersion
```{r}
# first, let's transform the phyloseq object into an MR experiment object
MRexp_objt<-phyloseq_to_metagenomeSeq(physeq_filtered)

# normalizes the object by cummulative sum scaling, a widely used method
cumNorm(MRexp_objt) 

#here you can access the abundance matrix normalized by cumulative sum scaling. you could overiwtte the phyloseq object with this
CSS_matrix <- MRcounts(MRexp_objt, norm = TRUE, log = TRUE) # using a log scale will essentially reduce the impact of common species and increase the impact of rare species

#make a new phyloseq object...
physeq_filtered_CSS<-physeq_filtered

# and now change it's taxa table
otu_table(physeq_filtered_CSS)<-otu_table(CSS_matrix, taxa_are_rows = TRUE)

#this is your final phyloseq object
physeq_filtered_CSS

#assing meja treatment as a factor
sample_data(physeq_filtered_CSS)$MeJA_treatment<-as.factor(sample_data(physeq_filtered_CSS)$MeJA_treatment)

#creating lists of phyloseq objects
# one list of 2 for B.ole and A.tha
pslist_sp_CSS<-phyloseq_sep_variable(physeq_filtered_CSS, variable = "Plant_species")
# one list of 2 phyloseq objects for root/soil samples
pslist_root_soil_CSS<-phyloseq_sep_variable(physeq_filtered_CSS, variable = "Sample_type") 
# one list of 4 phyloseq objects for sample type + species
ps_list_CSS<-phyloseq_sep_variable(physeq_filtered_CSS, variable = c("Plant_species","Sample_type"))


###########################


```
#### 1.4c list of different normalization options

```{r}

#now that we have multiple ways of looking at our data, let's make a list of different normalization options
normalization_listed<-list(physeq_filtered_CSS,physeq_filtered_rarefied,physeq_filtered)

names(normalization_listed)<-c("physeq_filtered_CSS",
                               "physeq_filtered_rarefied",
                               "physeq_filtered")
#this is a list of 3 phyloseq objects, each with a different normalization aproach
normalization_listed

```

# Data ready for analysis! proceed to scrip 2_Beta_Diversity!